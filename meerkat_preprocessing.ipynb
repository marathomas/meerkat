{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meerkat_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6DS7cV6PXtFd"
      ],
      "toc_visible": true,
      "mount_file_id": "124n_3kPigqSAruudn6PKtKARZqNZOyeu",
      "authorship_tag": "ABX9TyMag6pKJ6o02xGEHrkYP/d1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marathomas/meerkat/blob/master/meerkat_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObimIqrg4wDd",
        "colab_type": "text"
      },
      "source": [
        "# Meerkat Preprocessing\n",
        "\n",
        "In this script, I am preprocessing audio data so that I can reproduce the unsupervised clustering analysis performed by Gentner et al. 2019 (https://www.biorxiv.org/content/10.1101/870311v1.full.pdf) with meerkat vocalizations. I am planning to use the functions made available by Tim Sainsberg (https://github.com/timsainb/avgn_paper), a package called AVGN that should allow me to reproduce the analyses in the paper. Therefore, I need to bring my data into the format that is necessary to run the AVGN analysis functions.\n",
        "\n",
        "Thus, the aim of this script is to generate four types of files: \n",
        "- fileID_call[number].WAV files, each containing a meerkat call\n",
        "- fileID_noise[number].WAV files, each containing noise recorded prior or after a meerkat call\n",
        "- fileID_call[number].json files, each containing the metadata for a meerkat call\n",
        "- fileID_label.csv files\n",
        "\n",
        "The input to this script are long audio files usually containing up to 300 calls and csv files containing the start and stop times and labels of meerkat calls as annotated manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC7ORuA28opQ",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- Project folder should already exist, save path as PROJECT_PATH\n",
        "- Project folder must contain subfolder called \"in_labels\", containing all label tables in csv format \n",
        "- Project folder must contain subfolder called \"in_wavs\", containing all audio files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iftLETTORBW2",
        "colab_type": "text"
      },
      "source": [
        "### Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwlHh6zyNCMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAG0WSngwM5F",
        "colab_type": "text"
      },
      "source": [
        "Or select \"Mount Drive\" in Files menu!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TecLeuUBRC57",
        "colab_type": "text"
      },
      "source": [
        "### Installing and loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1c6YIpedD9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyViCmsAZVKl",
        "colab_type": "code",
        "outputId": "18d6aa6b-d9ad-46f6-9804-cbcf2a1fd030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.system('pip install pydub')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExebezW7wqPz",
        "colab_type": "text"
      },
      "source": [
        "(\"Currently, software installations within Google Colaboratory are not persistent, in that you must reinstall libraries every time you (re-)connect to an instance.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F5vdvXWeeZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "from IPython.display import Audio \n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import os\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import time\n",
        "from datetime import datetime\n",
        "import glob\n",
        "from pandas.core.common import flatten\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQH__8fWc2D",
        "colab_type": "text"
      },
      "source": [
        "### Setting constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHkKwuIE5KRM",
        "colab_type": "text"
      },
      "source": [
        "Setting project, input and output folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF038oa81Ggw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# these directories should already exist\n",
        "PROJECT_PATH = \"/content/drive/My Drive/meerkat/\" \n",
        "AUDIO_IN = PROJECT_PATH+\"in_wavs/\" \n",
        "LABELS_IN = PROJECT_PATH+\"in_labels/\" \n",
        "\n",
        "# these directories are created during execution\n",
        "AUDIO_OUT = PROJECT_PATH+\"segmented_audios/\" \n",
        "LABELS_OUT = PROJECT_PATH+\"labels/\"\n",
        "JSON_OUT = PROJECT_PATH+'json_files/'\n",
        "NOISE_OUT = PROJECT_PATH+'noise_files/'\n",
        "\n",
        "dirs2create = [AUDIO_OUT, LABELS_OUT, JSON_OUT, NOISE_OUT]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF8RjkKKWbD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_params = {\n",
        "    \"min_noise_ms\": 1000,\n",
        "    \"max_noise_ms\": 2000\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kadYPIvQipf",
        "colab_type": "text"
      },
      "source": [
        "Constants for parsing label files:\n",
        "\n",
        "- column names in labels CSV that indicate start and duration\n",
        "- irrelevant labels that are discarded in the process (labels for beeps, noise, synch calls..)\n",
        "- minimum call duration in ms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFBGs1ESQdsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START_COL = 'Start'\n",
        "DUR_COL = 'Duration'\n",
        "\n",
        "IRRELEVANT_LABELS = ['SYNCH', 'START', 'END', 'NOISE', 'BEEP', 'CHEW']\n",
        "IRRELEVANT_LABELS = IRRELEVANT_LABELS+[item.lower() for item in IRRELEVANT_LABELS]\n",
        "\n",
        "MIN_DURATION = 100 \n",
        "GROUP = 'HM'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DS7cV6PXtFd",
        "colab_type": "text"
      },
      "source": [
        "### Installing AVGN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z-B3QWa5Q_s",
        "colab_type": "text"
      },
      "source": [
        "Cloning the AVGN_paper repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDj26UYvRQb8",
        "colab_type": "code",
        "outputId": "84c6c1d6-1b2e-4445-cb67-616ea6bdd120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# not sure if this works, need to test it\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "if (not os.path.exists(PROJECT_PATH+'avgn_paper')):\n",
        "  os.mkdir(\"avgn_paper\")\n",
        "  os.chdir(\"avgn_paper\")\n",
        "  os.sytem('git clone https://github.com/timsainb/avgn_paper.git')\n",
        "else:\n",
        "  os.chdir(\"avgn_paper\")\n",
        "\n",
        "os.system('python setup.py develop')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMmnyr2Itwqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(PROJECT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ774UQVTMRq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a5b32ff-20e5-4389-c450-fd8b87dacca9"
      },
      "source": [
        "os.system('pip install pathlib2')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrK7a426tlxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-6vjukQBQib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0f242542-1cc5-4e3c-82c9-75690c011c19"
      },
      "source": [
        "from importlib.machinery import SourceFileLoader\n",
        "#avgn = SourceFileLoader('avgnpaper/avgn', join(PROJECT_PATH, 'utils/somelib.py')).load_module()\n",
        "avgn = SourceFileLoader('avgnpaper/avgn', PROJECT_PATH+'avgn_paper/avgn/'+'utils/__init__.py').load_module()\n",
        "import avgn"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/meerkat/avgn_paper/avgn/utils/general.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_JeTH34uJBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from avgn.utils.json import NoIndent, NoIndentEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eongzrt5WleI",
        "colab_type": "text"
      },
      "source": [
        "### Creating output directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRshpCmWx4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "for dirpath in dirs2create:\n",
        "  if not os.path.exists(os.path.basename(dirpath[:-1])):\n",
        "    os.mkdir(os.path.basename(dirpath[:-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4SE3XuA5pfl",
        "colab_type": "text"
      },
      "source": [
        "## Functions\n",
        "\n",
        "What I need are short .wav files, each containing one single vocalization of a meerkat. What I have are long .wav files, containing many vocalizations and periods of silence (noise), and a label file (CSV) indicating at what time vocalisations occur (and what type of vocalisation they are). In addition, I need a JSON metadata file for each vocalization .wav file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKH439GpqU5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(PROJECT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_nLCg2FK2p-",
        "colab_type": "text"
      },
      "source": [
        "### General"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkeWgn5k-5QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that gets fileID from csv filename\n",
        "# Input: csv_filename (not path!) (String)\n",
        "# Output: csv_filename up to the last numeric character\n",
        "\n",
        "def fileID_from_csv_filename(csv_in):\n",
        "  csv_in = csv_in[::-1]  # reverse string\n",
        "  def rem_nonnumeric(str): # removes everything up to the first numeric char\n",
        "    foundDigit=False\n",
        "    pos=0\n",
        "    for char in str:\n",
        "      if(char.isdigit()):\n",
        "        return(str[pos:])\n",
        "      pos=pos+1\n",
        "    return str \n",
        "  csv_out = rem_nonnumeric(csv_in)\n",
        "  csv_out = csv_out[::-1] # reverse to normal again\n",
        "  return (csv_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIPFuY9Z_XEX",
        "colab_type": "text"
      },
      "source": [
        "### Functions for parsing label files\n",
        "\n",
        "First, I'll parse the csv label files into a pandas dataframe. Then, because PyDub segments audio in milliseconds, I have to turn the format h:min:s.ms to ms, so that I have the start and stop times of the calls in milliseconds (f.e. 10032002-10032144)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQjo4cmKc9A9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that gets datatime object from timestring\n",
        "# timestring must match one of the given time_patterns\n",
        "# Input: some string containing a time (String)\n",
        "# Output: datetime object\n",
        "# Example usage: dt = get_time(\"01:02:30.555\")\n",
        "def get_time(timestring):\n",
        "    time_patterns = ['%H:%M:%S.%f', '%M:%S.%f']\n",
        "    for pattern in time_patterns:\n",
        "        try:\n",
        "            return datetime.strptime(timestring, pattern)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    print(\"Date is not in expected format\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# Function that converts time in datatime object to ms \n",
        "# Input: datatime (datatime.datatime)\n",
        "# Output: time in ms (float)\n",
        "# Example usage: ms = get_ms(datatime_obj)\n",
        "def get_ms(dt):\n",
        "    return dt.microsecond/1000+dt.second*1000 + dt.minute*60*1000 + dt.hour*60*60*1000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be8bfGLrlruT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that generates labels dataframe from csv file\n",
        "# - adds start and stop times of calls in milliseconds\n",
        "# - removes irrelevant labelled sections (noise, synch, beep etc.)\n",
        "# - removes labelled sections below minimum duration\n",
        "# Input: filepath to label csv (String)\n",
        "# Output: pandas dataframe, each row representing one call\n",
        "# Example usage: labels = parse_labels(label_filepath)\n",
        "\n",
        "def prep_labels(label_filepath):\n",
        "  print(\"Parsing...\")\n",
        "  # read in labels\n",
        "  labels = pd.read_csv(label_filepath, sep=\"\\t\")\n",
        "  \n",
        "  # Remove irrelevant labels\n",
        "  # find name of column that contains the labels. Should contain 'Name'\n",
        "  name_col = [col for col in labels.columns if 'Name' in col]\n",
        "  # hopefully only one result\n",
        "  if(len(name_col)==1):\n",
        "    name_col = name_col[0]\n",
        "    labels = labels[~labels[name_col].str.contains('|'.join(IRRELEVANT_LABELS))]\n",
        "  else:\n",
        "    print(\"Cannot find label name column\")\n",
        "  \n",
        "  # Add start stop ms\n",
        "  if (labels.shape[0]!=0):\n",
        "    labels['start_ms'] = labels.apply(lambda row: get_ms(get_time(row['Start'])), axis=1)\n",
        "    labels['duration_ms'] = labels.apply(lambda row: get_ms(get_time(row['Duration'])), axis=1)\n",
        "    labels['stop_ms'] = labels['start_ms']+labels['duration_ms']\n",
        "\n",
        "    # Remove super short calls (possibly mistakes?)\n",
        "    labels = labels.loc[labels['duration_ms'] >= MIN_DURATION]\n",
        "  \n",
        "  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn1GfNet_kpC",
        "colab_type": "text"
      },
      "source": [
        "### Functions for segmenting audio files\n",
        "\n",
        "I'll segment the audio files based on the timings given in the label files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWJlExrkprrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that generates audio chunks based on a label file that\n",
        "# provides start and stop times in ms\n",
        "# Input: filepath to audiofile (.wav) (String), \n",
        "#        filepath to labelsfile (.csv) (String)\n",
        "# Output: None, audio chunks are exported in current working directory, named\n",
        "#         filename_call_[number].wav (numbered 1,2,3...)\n",
        "# Example usage: generate_audio_chunks(audio_filepath, label_filepath)\n",
        "\n",
        "def generate_audio_chunks(audio_filepath, label_filepath):\n",
        "  \n",
        "  print(\"Processing \"+os.path.basename(audio_filepath))\n",
        "\n",
        "  # Parse labels\n",
        "  labels = prep_labels(label_filepath)\n",
        "  \n",
        "  # If labels is non-empty...\n",
        "  if (labels.shape[0]!=0):\n",
        "    # Create audio chunks based on start and stop ms \n",
        "    print(\"Chunking...\")\n",
        "    audio_filename = os.path.basename(audio_filepath)\n",
        "    audio = AudioSegment.from_wav(audio_filepath)\n",
        "    chunks = labels.apply(lambda row: (audio[row['start_ms']:row['stop_ms']]), axis = 1)\n",
        "\n",
        "    # export chunks in current working directory\n",
        "    chunks.index=range(chunks.shape[0])\n",
        "    for index, content in chunks.items():\n",
        "      content.export((audio_filename[:-4]+\"_call\"+str(index)+\".wav\"), format=\"wav\")\n",
        "  \n",
        "  # save modified labels file\n",
        "    labels['audio_file'] = [audio_filename[:-4]+\"_call\"+str(i)+\".wav\" for i in range(labels.shape[0])]\n",
        "    labels.to_csv(LABELS_OUT+audio_filename[:-4]+\"_labels.csv\")\n",
        "\n",
        "  else:\n",
        "    print(\"No labelled calls for \"+os.path.basename(audio_filepath))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sIDNFfyP_uz",
        "colab_type": "text"
      },
      "source": [
        "### Functions for generating noise files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJU9OLW8QFKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to generate noise file for a call wav\n",
        "# Input: filepath to call wav (String), \n",
        "#        filepath to full wav (String), \n",
        "#        filepath to label csv (String),\n",
        "#        fileID (String), \n",
        "#        Parameters for generating noise file (Dict)\n",
        "# Output: returns file name of noise wav file or NA (String), \n",
        "#         generates noise file in NOISE_OUT directory\n",
        "# Comments: - uses subfunctions extract_noise_pre and extract_noise_post\n",
        "#           - adapted from Sainsberg\n",
        "\n",
        "def generate_noisewav(call_filepath, wav_filepath, label_filepath, fileID, noise_params):\n",
        "\n",
        "  noise_file = \"NA\"  \n",
        "  call_filename = os.path.basename(call_filepath)\n",
        "  # not pretty but should work to get the call number\n",
        "  # [:-4] to remove .wav, split _call to get number behind _call\n",
        "  # (could also take row number of label table)\n",
        "  call_num = call_filename[:-4].split(\"_call\")[1]\n",
        "  label_table = pd.read_csv(label_filepath)\n",
        "\n",
        "  # these need to be converted to seconds\n",
        "  call_start = label_table.loc[label_table['audio_file']==call_filename, 'start_ms'].values[0]/1000\n",
        "  call_end = label_table.loc[label_table['audio_file']==call_filename, 'stop_ms'].values[0]/1000\n",
        "  \n",
        "  min_noise_size = noise_params[\"min_noise_ms\"]/1000\n",
        "  max_noise_size = noise_params[\"max_noise_ms\"]/1000\n",
        "\n",
        "  all_call_ends = np.asarray(label_table['stop_ms'])/1000\n",
        "\n",
        "  # try to get noise from pre call\n",
        "  noise_clip, sr = extract_noise_pre(call_start, call_end, wav_filepath, all_call_ends, min_noise_size, max_noise_size)\n",
        "  if noise_clip is None:\n",
        "    # try to get noise from post call\n",
        "    all_call_starts = np.asarray(label_table['start_ms'])/1000\n",
        "    noise_clip, sr = extract_noise_post(call_start, call_end, wav_filepath, all_call_starts, min_noise_size, max_noise_size)\n",
        "  \n",
        "  # save noise file (if one could be generated)\n",
        "  if noise_clip is not None:\n",
        "    librosa.output.write_wav(NOISE_OUT+fileID+'_noise'+call_num+'.wav', y=noise_clip, sr=sr, norm=True)\n",
        "    noise_file = fileID+'_noise'+call_num+'.wav'\n",
        "\n",
        "  return noise_file\n",
        "\n",
        "\n",
        "def extract_noise_pre(call_start, call_end, wav_filepath, all_call_ends, min_noise_size, max_noise_size):\n",
        "  # try to get a noise clip from the time preceding this clip\n",
        "  if call_start > min_noise_size:\n",
        "    # get time of preceding pulses\n",
        "    td = call_start - all_call_ends\n",
        "    td = td[td > 0]\n",
        "    # if there is anything within this timeframe, this timeframe is unusable\n",
        "    if not np.any(td < min_noise_size):\n",
        "      # get times for noise clip\n",
        "      noise_start = call_start - np.min(\n",
        "          list(td - 1) + [max_noise_size]\n",
        "          )\n",
        "      noise_end = call_start\n",
        "\n",
        "      # load the clip\n",
        "      noise_clip, sr = librosa.load(\n",
        "          wav_filepath,\n",
        "          mono=True,\n",
        "          sr=None,\n",
        "          offset=noise_start,\n",
        "          duration=(noise_end - noise_start),\n",
        "          )\n",
        "      return noise_clip, sr\n",
        "  return None, None\n",
        "\n",
        "\n",
        "def extract_noise_post(call_start, call_end, wav_filepath, all_call_starts, min_noise_size, max_noise_size):\n",
        "  # try to get noise clip from end of file\n",
        "  wav_duration = (librosa.get_duration(filename=wav_filepath))\n",
        "  if wav_duration - call_end > min_noise_size:\n",
        "    td = all_call_starts - call_end\n",
        "    td = td[td > 0]\n",
        "    if not np.any(td < min_noise_size):\n",
        "      # get times for noise clip\n",
        "      noise_start = call_end\n",
        "      noise_end = call_end + np.min(\n",
        "          list(td - min_noise_size / 2)\n",
        "          + [max_noise_size]\n",
        "          )\n",
        "      # load the clip\n",
        "      noise_clip, sr = librosa.load(\n",
        "          wav_filepath,\n",
        "          mono=True,\n",
        "          sr=None,\n",
        "          offset=noise_start,\n",
        "          duration=(noise_end - noise_start),\n",
        "          )\n",
        "      return noise_clip, sr\n",
        "  return None, None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moGTC3EollBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf592c3a-cad0-4ba0-ff89-10c250114e71"
      },
      "source": [
        "fileIDs"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HM_RT_R12_file_6_(2017_08_25-06_44_59)_ASWMUX221102',\n",
              " 'HM_VLF206_SOUNDFOC_20170825_2',\n",
              " 'HM_VHMM003_SOUNDFOC_20170825_2',\n",
              " 'HM_VHMM003_SOUNDFOC_20170825_3',\n",
              " 'HM_HRT_R09_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221110',\n",
              " 'HM_LT_R07_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221092',\n",
              " 'HM_HTB_R14_file_6_(2017_08_25-06_44_59)_ASWMUX221052',\n",
              " 'HM_PET_R11_20170903-20170908_file_4_(2017_09_05-05_44_59)_ASWMUX221163',\n",
              " 'HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_ASWMUX221163',\n",
              " 'HM_RT_R12_file_4_(2017_08_23-06_44_59)_ASWMUX221102',\n",
              " 'HM_VLF206_SOUNDFOC_20170824_1',\n",
              " 'HM_PET_R11_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221163',\n",
              " 'HM_HRT_R09_AUDIO_file_5_(2017_08_24-06_44_59)_ASWMUX221110',\n",
              " 'HM_LT_R07_AUDIO_file_4_(2017_08_23-06_44_59)_ASWMUX221092',\n",
              " 'HM_HRT_R09_AUDIO_file_4_(2017_08_23-06_44_59)_ASWMUX221110',\n",
              " 'HM_VLF206_SOUNDFOC_20170823_1',\n",
              " 'HM_RT_R12_file_5_(2017_08_24-06_44_59)_ASWMUX221102',\n",
              " 'HM_LT_R09_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221110',\n",
              " 'HM_HRT_R07_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221092',\n",
              " 'HM_VHMM003_SOUNDFOC_20170824_2',\n",
              " 'HM_HMB_R11_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221163',\n",
              " 'HM_VHMM003_SOUNDFOC_20170905_4',\n",
              " 'HM_VLF206_SOUNDFOC_20170825_1',\n",
              " 'HM_PET_R11_20170903-20170908_file_3_(2017_09_04-05_44_59)_ASWMUX221163',\n",
              " 'HM_VHMM002_HRT_AUDIO_R09_file_6_(2017_08_07-06_44_59)_ASWMUX221110',\n",
              " 'HM_VCVM001_SOUNDFOC_20190712_2',\n",
              " 'HM_VCVM001_SOUNDFOC_20190712_1',\n",
              " 'HM_VHMF010_SOUNDFOC_20190712',\n",
              " 'HM_VHMM007_LSLT_R17_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMM007_LSLT_R17_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMM008_SHTB_R14_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMM023_MBLS_R02_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMM023_MBLS_R02_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMF015_RTTB_R05_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMF019_MBTB_R25_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMF022_MBRS_R22_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMM021_MBLT_R01_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMF019_MBTB_R25_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMF015_RTTB_R05_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMM014_LSTB_R19_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMM016_LTTB_R29_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMM017_RSTB_R23_20190708-20190720_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMM017_RSTB_R23_20190708-20190720_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMM021_MBLT_R01_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMF022_MBRS_R22_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VHMF010_SOUNDFOC_20190713',\n",
              " 'HM_VHMF001_HTB_R20_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944',\n",
              " 'HM_VCVM001_SOUNDFOC_20190713_1',\n",
              " 'HM_VHMF019_MBTB_R25_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMF001_HTB_R20_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_RT_R10_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221102',\n",
              " 'HM_HTB_R14_file_4_(2017_08_23-06_44_59)_ASWMUX221052',\n",
              " 'HM_VHMM002_HRT_AUDIO_R09_file_5_(2017_08_06-06_44_59)_ASWMUX221110',\n",
              " 'HM_HMB_R11_AUDIO_file_5_(2017_08_24-06_44_59)_ASWMUX221163',\n",
              " 'HM_HTB_R14_file_5_(2017_08_24-06_44_59)_ASWMUX221052',\n",
              " 'HM_VCVM001_HMB_AUDIO_R08_ file_2_(2017_08_03-06_44_59)_ASWMUX221153',\n",
              " 'HM_VLF206_SOUNDFOC_20170806_4',\n",
              " 'HM_VLF206_SOUNDFOC_20170905_1',\n",
              " 'HM_VLF206_SOUNDFOC_20170806_3',\n",
              " 'HM_VLF206_SOUNDFOC_20170903',\n",
              " 'HM_VHMM003_SOUNDFOC_20170905_3',\n",
              " 'HM_VLF206_SOUNDFOC_20170905_2',\n",
              " 'HM_VLF206_SOUNDFOC_20170824_2',\n",
              " 'HM_VLF206_SOUNDFOC_20170823_2',\n",
              " 'HM_VLF206_SOUNDFOC_20170806_2',\n",
              " 'HM_LT_R07_AUDIO_file_5_(2017_08_24-06_44_59)_ASWMUX221092',\n",
              " 'HM_VHMF022_MBRS_R22_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMF019_MBTB_R25_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMF015_RTTB_R05_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMM021_MBLT_R01_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMM017_RSTB_R23_20190708-20190720_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMM014_LSTB_R19_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMF001_HTB_R20_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMM021_MBLT_R01_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMM017_RSTB_R23_20190708-20190720_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMF022_MBRS_R22_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMF010_SOUNDFOC_20190715',\n",
              " 'HM_VHMM023_MBLS_R02_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMM016_LTTB_R29_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMM008_SHTB_R14_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMM023_MBLS_R02_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMM007_LSLT_R17_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMF015_RTTB_R05_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VHMF010_SOUNDFOC_20190714',\n",
              " 'HM_VHMM017_RSTB_R23_20190708-20190720_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMM014_LSTB_R19_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMM007_LSLT_R17_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VCVM001_SOUNDFOC_20190716_2',\n",
              " 'HM_VCVM001_SOUNDFOC_20190716_1',\n",
              " 'HM_VHMM007_LSLT_R17_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMF022_MBRS_R22_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMF019_MBTB_R25_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMF015_RTTB_R05_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VCVM001_SOUNDFOC_20190714_1',\n",
              " 'HM_VHMM008_SHTB_R14_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944',\n",
              " 'HM_VHMM021_MBLT_R01_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMM023_MBLS_R02_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMM008_SHTB_R14_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VHMF001_HTB_R20_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944',\n",
              " 'HM_VCVM001_SOUNDFOC_20190715_1',\n",
              " 'HM_VHMF001_HTB_R20_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944',\n",
              " 'HM_VHMM017_RSTB_R23_20190708-20190720_file_11_(2019_07_17-11_44_59)_175944',\n",
              " 'HM_VHMM008_SHTB_R14_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944',\n",
              " 'HM_VCVM001_SOUNDFOC_HM_20190717',\n",
              " 'HM_VHMF010_SOUNDFOC_HM_20190717_2',\n",
              " 'HM_VHMF010_SOUNDFOC_HM_20190717_1',\n",
              " 'HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163',\n",
              " 'HM_VHMF001_HTB_AUDIO_R07_file_5_(2017_08_06-06_44_59)_ASWMUX221092',\n",
              " 'HM_VHMM003_HLT_AUDIO_R12_file_5_(2017_08_06-06_44_59)_ASWMUX221102',\n",
              " 'HM_VHMM006_RT_AUDIO_R14_file_5_(2017_08_06-06_44_59)_ASWMUX221052',\n",
              " 'HM_HRT_R07_20170903-20170908_file_4_(2017_09_05-05_44_59)_ASWMUX221092',\n",
              " 'HM_VCVM001_AUDIO_file_5_(2017_08_06-06_44_59)_ASWMUX221153',\n",
              " 'HM_RT_R10_20170903-20170908_file_4_(2017_09_05-05_44_59)_ASWMUX221102',\n",
              " 'HM_HTB_R14_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221052',\n",
              " 'HM_LT_R09_20170903-20170908_file_4_(2017_09_05-05_44_59)_ASWMUX221110',\n",
              " 'HM_VHMM003_SOUNDFOC_20170905_2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2fXvAmGmG-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_ID = fileIDs[10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzegcgeOmEN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26283a2e-0dec-4735-ec36-4cb9fcac2b6e"
      },
      "source": [
        "example_ID = fileIDs[10]\n",
        "print(example_ID)\n",
        "print(example_ID[(len(GROUP)+1):].split('_')[0])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HM_VLF206_SOUNDFOC_20170824_1\n",
            "VLF206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccG0KNwK1642",
        "colab_type": "text"
      },
      "source": [
        "### Functions for generating JSON files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfFxwmsksvKm",
        "colab_type": "text"
      },
      "source": [
        "From AVGN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFgxTaH116Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get the meerkat ID (alphanumeric String) from filename\n",
        "# filename is always HM_meerkatID_*.extension\n",
        "# Input: filename (String)\n",
        "# Output: meerkat ID (String)\n",
        "# Example use: get_meerkatID('HM_VHMM003_HLT_AUDIO_R12_file_5_(2017_08_06-06_44_59)_ASWMUX221102.wav')\n",
        "\n",
        "def get_meerkatID(filename):\n",
        "  meerkatID = filename.replace(GROUP+'_','')\n",
        "  meerkatID = str.split(meerkatID, sep='_')[0]\n",
        "  return meerkatID\n",
        "\n",
        "# Function to get date from filename\n",
        "# date in filename must be in one of the three patterns\n",
        "# Input: filename (String)\n",
        "# Output: datetime object\n",
        "# Example use: get_datetime('HM_VHMF001_HTB_R20_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944')\n",
        "\n",
        "def get_datetime(filename):\n",
        "  import re, datetime\n",
        "  s = \"I have a meeting on 2018-12-10 in New York\"\n",
        "  match = re.search('\\d{4}-\\d{2}-\\d{2}', filename)\n",
        "  if (match):\n",
        "    date = datetime.datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
        "  else:\n",
        "    match = re.search('\\d{4}_\\d{2}_\\d{2}', filename)\n",
        "    if (match):\n",
        "     date = datetime.datetime.strptime(match.group(), '%Y_%m_%d').date() \n",
        "    else:\n",
        "      match = re.search('\\d{4}\\d{2}\\d{2}', filename)\n",
        "      if(match):\n",
        "        date = datetime.datetime.strptime(match.group(), '%Y%m%d').date()\n",
        "  return date\n",
        "\n",
        "# TODO\n",
        "# Function to generate JSON file for call wav\n",
        "# Input: filepath to call wav (String), filepath to full wav (String), filepath to label csv (String), \n",
        "# Output: location of JSON file, generates JSON files in JSON_OUT directory\n",
        "\n",
        "def generate_json(call_filepath, wav_filepath, label_filepath, fileID, noise_wav):\n",
        "\n",
        "  wav_date, sr, wav_duration, bout_number, indv, json_out= \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\"\n",
        "  \n",
        "  wav_date = get_datetime(fileID).strftime(\"%Y-%m-%d\")\n",
        "  wav_duration = librosa.get_duration(filename=call_filepath)\n",
        "  y,sr = librosa.load(call_filepath) #get_samplerate doesn't work with librosa 0.6\n",
        "  bout_number = os.path.basename(call_filepath)[:-4].split('_call')[1]\n",
        "  indv = get_meerkatID(fileID)\n",
        "    \n",
        "  # wav general information\n",
        "  json_dict = {}\n",
        "  json_dict[\"datetime\"] = wav_date\n",
        "  json_dict[\"samplerate_hz\"] = sr\n",
        "  json_dict[\"length_s\"] = wav_duration\n",
        "  json_dict[\"species\"] = \"Suricata suricatta\"\n",
        "  json_dict[\"common_name\"] = \"Meerkat\"\n",
        "  json_dict[\"wav_loc\"] = call_filepath\n",
        "  json_dict[\"bout_number\"] = bout_number\n",
        "  json_dict[\"original_wav\"] = wav_filepath\n",
        "  json_dict[\"noise_loc\"] = noise_wav\n",
        "  json_dict[\"indv\"] = indv\n",
        "    \n",
        "  json_txt = json.dumps(json_dict, cls=NoIndentEncoder, indent=2)\n",
        "  json_out = JSON_OUT+(os.path.basename(call_filepath)[:-4]+\".JSON\")\n",
        "\n",
        "  # save json\n",
        "  print(json_txt, file=open(json_out, \"w\"))\n",
        "\n",
        "  return json_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuH02Fq3h6wb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99812754-b595-4d25-ec34-55478032a69a"
      },
      "source": [
        "example_filename = fileIDs[100]\n",
        "print(example_filename)\n",
        "print(get_datetime(example_filename))\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HM_VHMF001_HTB_R20_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944\n",
            "2019-07-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjtDjnHLt4ET",
        "colab_type": "text"
      },
      "source": [
        "## Processing files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw0bCcsAOmD9",
        "colab_type": "text"
      },
      "source": [
        "### Setting variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GcTYb6E_GOg",
        "colab_type": "text"
      },
      "source": [
        "Getting list of csvs and matching wavs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQVZb9G3_BWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting list of fileIDs, wavs and csvs (fileID, in_wav_loc and in_csv_loc)\n",
        "\n",
        "in_csv_loc = glob.glob(LABELS_IN+'*.csv') + glob.glob(LABELS_IN+'*.CSV')\n",
        "csv_filenames = [os.path.basename(csv) for csv in in_csv_loc]\n",
        "\n",
        "fileIDs = [fileID_from_csv_filename(csv_filename) for csv_filename in csv_filenames]\n",
        "\n",
        "in_wav_loc = [glob.glob(AUDIO_IN+fileID+'*') for fileID in fileIDs] # creates list of lists\n",
        "in_wav_loc = [[\"NA\"] if not x else x for x in in_wav_loc] # Replace empty lists with \"NA\"\n",
        "in_wav_loc = list(flatten(in_wav_loc)) # Flatten list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LohkmDcgVC0",
        "colab_type": "text"
      },
      "source": [
        "For now, only use random subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfN0QThbZ9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_csv_loc = in_csv_loc[18:23]+in_csv_loc[50:55]+in_csv_loc[90:95]\n",
        "in_wav_loc = in_wav_loc[18:23]+in_wav_loc[50:55]+in_wav_loc[90:95]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3Kk_BqcsWn2",
        "colab_type": "text"
      },
      "source": [
        "### Removing poor quality files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXqw6cd8saEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "badIDs = ['HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163', \n",
        "           'HM_VHMM006_RT_AUDIO_R14_file_5_(2017_08_06-06_44_59)_ASWMUX221052']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgasxnU8tAvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_csvs = [glob.glob(LABELS_IN+fileID+'*') for fileID in badIDs]\n",
        "bad_csvs = list(flatten(bad_csvs))\n",
        "\n",
        "bad_wavs = []\n",
        "for bad_csv in bad_csvs:\n",
        "  bad_wavs.append(in_wav_loc[in_csv_loc.index(bad_csv)])\n",
        "\n",
        "for bad_csv in bad_csvs:\n",
        "  in_csv_loc.remove(bad_csv)\n",
        "for bad_wav in bad_wavs:\n",
        "  in_wav_loc.remove(bad_wav)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oYWlOSQjwtV",
        "colab_type": "text"
      },
      "source": [
        "### Segmenting audio files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ZyqxtiUO0Y",
        "colab_type": "text"
      },
      "source": [
        "Segmenting the audio files in AUDIO_IN into smaller chunks, each containing one call. Start and stop times of calls are taken from label files (csv) in LABELS_IN folder. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqdDBxKS_bAU",
        "colab_type": "text"
      },
      "source": [
        "generate_audio_chunks generates audio chunks based on a label file that provides start and stop times in ms. It takes a filepath to audiofile (.wav) (String) and a filepath to labelsfile (.csv) (String) as input. The output is none, but audio chunks are exported in AUDIO_OUT directory, named filename_call_[number].wav (numbered 1,2,3...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzVT1O2oPBK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(AUDIO_OUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjUc_ZGyuAJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "6711f8f7-255d-4483-8025-060f2664d573"
      },
      "source": [
        "for wav, csv in zip(in_wav_loc, in_csv_loc):\n",
        "  if not wav=='NA':\n",
        "    generate_audio_chunks(wav, csv)\n",
        "  else:\n",
        "    print(\"No matching audio for: \"+csv)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing HM_HRT_R07_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221092.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMM003_SOUNDFOC_20170824_2.WAV\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_HMB_R11_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221163.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "No matching audio for: /content/drive/My Drive/meerkat/in_labels/HM_VHMM003_SOUNDFOC_20170905_4_label.csv\n",
            "Processing HM_VLF206_SOUNDFOC_20170825_1.WAV\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VCVM001_SOUNDFOC_20190712_1.WAV\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMF019_MBTB_R25_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMF019_MBTB_R25_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMF022_MBRS_R22_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMF019_MBTB_R25_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMF022_MBRS_R22_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMM023_MBLS_R02_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMM023_MBLS_R02_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMM023_MBLS_R02_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944.wav\n",
            "Parsing...\n",
            "Chunking...\n",
            "Processing HM_VHMM023_MBLS_R02_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944.wav\n",
            "Parsing...\n",
            "Chunking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dozjF6Mzu8AM",
        "colab_type": "code",
        "outputId": "3fceafe0-5c67-44ba-c343-62406c63c6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Generated \"+str(len(glob.glob(LABELS_OUT+'*')))+\" label files\")\n",
        "print(\"Generated \"+str(len(glob.glob(AUDIO_OUT+'*')))+\" audio chunks\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated 14 label files\n",
            "Generated 2671 audio chunks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh2jMtTP9Sx3",
        "colab_type": "text"
      },
      "source": [
        "From processing most of the 2017 files:\n",
        "(need to update this section later)\n",
        "\n",
        "Segmented audios were generated for all files, except:\n",
        "\n",
        "- files where all labels were something other than calls:\n",
        "  - HM_VHMM002_HRT_AUDIO_R09_file_5_(2017_08_06-06_44_59)_ASWMUX221110 \n",
        "\n",
        "- files where where there was no matching wav file:\n",
        "  - HM_VHMM003_SOUNDFOC_20170905_2 (in short list)\n",
        "  - HM_VLF206_SOUNDFOC_20170903\n",
        "  - HM_VHMM003_SOUNDFOC_20170905_4 (in short list)\n",
        "  - HM_VHMM003_SOUNDFOC_20170905_3\n",
        "  - HM_VLF206_SOUNDFOC_20170905_2\n",
        "  - HM_VLF206_SOUNDFOC_20170905_1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rDW_Qsfvnon",
        "colab_type": "text"
      },
      "source": [
        "### Get updated list of wav and labels file locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC7VfmA2YhvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of all wav filepaths (to full wav files, not just the calls), where I have \n",
        "# a labels file in LABELS_OUT. Therefore, do it kind of backwards.\n",
        "\n",
        "labels_loc = glob.glob(LABELS_OUT+'*.csv')\n",
        "fileIDs = [os.path.basename(item).replace('_labels.csv', '') for item in labels_loc] \n",
        "\n",
        "wavs_loc = [glob.glob(AUDIO_IN+fileID+'*') for fileID in fileIDs] # creates list of lists\n",
        "wavs_loc = [[\"NA\"] if not x else x for x in wavs_loc] # Replace empty lists with \"NA\"\n",
        "wavs_loc = list(flatten(wavs_loc)) # Flatten list\n",
        "\n",
        "# check for NAs, should be none!\n",
        "for ID, wav in zip(fileIDs, wavs_loc):\n",
        "  if wav==\"NA\":\n",
        "    print(\"Error, wav file missing for\"+label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKj_p7K3_zpW",
        "colab_type": "text"
      },
      "source": [
        "### Generating noise files\n",
        "\n",
        "Generating the noise file (a wav of the 1-2s prior of after a call if not another call occurs in this time window). Can be used later to denoise the call wav. The noise files are saved in the NOISE_OUT folder and labelled: \n",
        "- fileID_noise[call_number].wav\n",
        "\n",
        "A column 'noise_wav' is added to the fileIDlabels.csv containing either the noise filename or \"NA\" if no noise file could be generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWlwDQOxAO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(PROJECT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xODO21FjzlMO",
        "colab_type": "text"
      },
      "source": [
        "Noise file generation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP0FMjVk2E6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e63f6ab6-3860-411b-c4dd-ad4aaa27792f"
      },
      "source": [
        "# for each long wav file\n",
        "for wav_filepath, label_filepath, fileID in zip(wavs_loc, labels_loc, fileIDs):\n",
        "  #fileID = os.path.basename(wav_filepath).replace('.wav', '')\n",
        "  print(\"Generating noise files for \"+fileID)\n",
        "  # find the matching label file\n",
        "  #label_filepath = glob.glob(LABELS_OUT+fileID+'*.csv')[0]\n",
        "  # generate list of call wavs assigned to it\n",
        "  call_filepathList = glob.glob(AUDIO_OUT+fileID+'*.wav')\n",
        "\n",
        "  # Then:\n",
        "  # for each call wav\n",
        "  noise_wavs = []\n",
        "  for call_filepath in call_filepathList:\n",
        "\n",
        "    # generate NOISE file\n",
        "    # append location of noise wav to noise_wavs list\n",
        "    result = generate_noisewav(call_filepath, wav_filepath, label_filepath, fileID, noise_params)\n",
        "    noise_wavs.append(result)\n",
        "    #noise_wavs.append(generate_noisewav(call_filepath, wav_filepath, label_filepath, fileID, noise_params))\n",
        "  \n",
        "  # add noise_wav column to labels.csv files\n",
        "  lable_table = pd.read_csv(label_filepath)\n",
        "  lable_table['noise_wav'] = noise_wavs\n",
        "  lable_table.to_csv(label_filepath)\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating noise files for HM_VHMM003_SOUNDFOC_20170824_2\n",
            "Generating noise files for HM_HMB_R11_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221163\n",
            "Generating noise files for HM_VLF206_SOUNDFOC_20170825_1\n",
            "Generating noise files for HM_VCVM001_SOUNDFOC_20190712_1\n",
            "Generating noise files for HM_VHMF019_MBTB_R25_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944\n",
            "Generating noise files for HM_VHMF019_MBTB_R25_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944\n",
            "Generating noise files for HM_VHMF022_MBRS_R22_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944\n",
            "Generating noise files for HM_VHMF019_MBTB_R25_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944\n",
            "Generating noise files for HM_VHMF022_MBRS_R22_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944\n",
            "Generating noise files for HM_VHMM023_MBLS_R02_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944\n",
            "Generating noise files for HM_VHMM023_MBLS_R02_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944\n",
            "Generating noise files for HM_VHMM023_MBLS_R02_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944\n",
            "Generating noise files for HM_VHMM023_MBLS_R02_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2DPkdNt0UMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "899387f6-006f-46f6-9951-c2ab46155741"
      },
      "source": [
        "print(len(os.listdir(NOISE_OUT)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iil-IL0QvJ1D",
        "colab_type": "text"
      },
      "source": [
        "### Generating JSON files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwuaM0fbvbvG",
        "colab_type": "text"
      },
      "source": [
        "Again need all filepaths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P9D2AOeoGIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of all wav filepaths (to full wav files, not just the calls), where I have \n",
        "# a labels file in LABELS_OUT. Therefore, do it kind of backwards.\n",
        "\n",
        "labels_loc = glob.glob(LABELS_OUT+'*.csv')\n",
        "fileIDs = [os.path.basename(item).replace('_labels.csv', '') for item in labels_loc] \n",
        "\n",
        "wavs_loc = [glob.glob(AUDIO_IN+fileID+'*') for fileID in fileIDs] # creates list of lists\n",
        "wavs_loc = [[\"NA\"] if not x else x for x in wavs_loc] # Replace empty lists with \"NA\"\n",
        "wavs_loc = list(flatten(wavs_loc)) # Flatten list\n",
        "\n",
        "# check for NAs, should be none!\n",
        "for ID, wav in zip(fileIDs, wavs_loc):\n",
        "  if wav==\"NA\":\n",
        "    print(\"Error, wav file missing for\"+label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkHUzVEEzA4w",
        "colab_type": "text"
      },
      "source": [
        "Using the same loop as in noise files. A little redundant but I wanted to leave these steps separate so that I can more easily re-do  single steps in the pipeline.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am9PFfAEziIk",
        "colab_type": "text"
      },
      "source": [
        "JSON file generation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1xlsQLKy2mF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "94228282-65d5-4db5-cee0-47dda3e03dea"
      },
      "source": [
        "# for each long wav file\n",
        "for wav_loc, label_loc, fileID in zip(wavs_loc, labels_loc, fileIDs):\n",
        "\n",
        "  print(\"Generating JSON for \"+fileID)\n",
        "  # generate list of call wavs assigned to it\n",
        "  call_filepathList = glob.glob(AUDIO_OUT+fileID+'*.wav')\n",
        "\n",
        "  # for each call wav\n",
        "  json_files = []\n",
        "  for call_filepath in call_filepathList:\n",
        "    # generate JSON file\n",
        "    bout_num = os.path.basename(call_filepath)[:-4].split('_call')[1]\n",
        "    noise_wav = NOISE_OUT+fileID+'_noise'+bout_num+'.wav'\n",
        "    json_files.append(generate_json(call_filepath, wav_loc, label_loc, fileID, noise_wav))\n",
        "  \n",
        "  # add json file column to labels.csv files\n",
        "  lable_table = pd.read_csv(label_loc)\n",
        "  lable_table['json_file'] = json_files\n",
        "  lable_table.to_csv(label_loc)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating JSON for HM_HRT_R07_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221092\n",
            "Generating JSON for HM_VHMM003_SOUNDFOC_20170824_2\n",
            "Generating JSON for HM_HMB_R11_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221163\n",
            "Generating JSON for HM_VLF206_SOUNDFOC_20170825_1\n",
            "Generating JSON for HM_VCVM001_SOUNDFOC_20190712_1\n",
            "Generating JSON for HM_VHMF019_MBTB_R25_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944\n",
            "Generating JSON for HM_VHMF019_MBTB_R25_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944\n",
            "Generating JSON for HM_VHMF022_MBRS_R22_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944\n",
            "Generating JSON for HM_VHMF019_MBTB_R25_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944\n",
            "Generating JSON for HM_VHMF022_MBRS_R22_20190707-20190719_file_7_(2019_07_13-11_44_59)_135944\n",
            "Generating JSON for HM_VHMM023_MBLS_R02_20190707-20190719_file_8_(2019_07_14-11_44_59)_145944\n",
            "Generating JSON for HM_VHMM023_MBLS_R02_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944\n",
            "Generating JSON for HM_VHMM023_MBLS_R02_20190707-20190719_file_10_(2019_07_16-11_44_59)_165944\n",
            "Generating JSON for HM_VHMM023_MBLS_R02_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhyjHdTCv-ZF",
        "colab_type": "text"
      },
      "source": [
        "# Code-Reste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgRaoWnU0elr",
        "colab_type": "text"
      },
      "source": [
        "### Checking what files are present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQY1ZFTo0chn",
        "colab_type": "code",
        "outputId": "e69a6310-8fa7-4ca2-fe84-d5971c18ca88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Checking which files are uploaded and which aren't even though they should have been\n",
        "\n",
        "years = ['2017', '2019']\n",
        "\n",
        "for year in years:\n",
        "  print(\"Year is: \"+year)\n",
        "  matching = pd.read_csv(PROJECT_PATH+\"/matching_\"+year+\".txt\", sep=\"\\t\", header=None)\n",
        "  matching.columns = ['name', 'wav', 'csv']\n",
        "\n",
        "  print(matching.shape)\n",
        "  matching = matching.dropna()\n",
        "  print(\"After dropping NA:\")\n",
        "  print(matching.shape)\n",
        "\n",
        "  wavs_file = [os.path.basename(x) for x in matching['wav']]\n",
        "  if(year=='2017'):\n",
        "    audio_dir = AUDIO_IN\n",
        "  elif(year=='2019'):\n",
        "    audio_dir = PROJECT_PATH+'matched_wavs_2019'\n",
        "  \n",
        "  wavs_drive = os.listdir(audio_dir)\n",
        "\n",
        "  if(len(set(wavs_drive))==len(wavs_drive)):\n",
        "    print(\"No duplicates\")\n",
        "  else:\n",
        "    print(\"Duplicates!\")\n",
        "\n",
        "  diffs = pd.Series(list(set(wavs_drive).difference(set(wavs_file))))\n",
        "  print(\"In drive, but not in file:\"+str(diffs.size))\n",
        "  print(diffs)\n",
        "\n",
        "  diffs = pd.Series(list(set(wavs_file).difference(set(wavs_drive))))\n",
        "  print(\"In file, but not in drive:\"+str(diffs.size))\n",
        "  print(diffs)\n",
        "  diffs.to_csv(PROJECT_PATH+'diffs'+year+'.csv', sep=\";\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Year is: 2017\n",
            "(51, 3)\n",
            "After dropping NA:\n",
            "(45, 3)\n",
            "No duplicates\n",
            "In drive, but not in file:0\n",
            "Series([], dtype: float64)\n",
            "In file, but not in drive:0\n",
            "Series([], dtype: float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Year is: 2019\n",
            "(65, 3)\n",
            "After dropping NA:\n",
            "(65, 3)\n",
            "No duplicates\n",
            "In drive, but not in file:0\n",
            "Series([], dtype: float64)\n",
            "In file, but not in drive:0\n",
            "Series([], dtype: float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mNKIoUefcIM",
        "colab_type": "text"
      },
      "source": [
        "### Moving files into different folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLpxWfylfnv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(PROJECT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtxydmK1fkm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(os.listdir(\"in_wavs\")))\n",
        "print(len(os.listdir(\"matched_wavs_2019\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqrQyAF-fbkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move all files from matched_wavs_2019 into in_wavs\n",
        "files2move = os.listdir(\"matched_wavs_2019\")\n",
        "for f in files2move:\n",
        "  shutil.move(PROJECT_PATH+'matched_wavs_2019/'+f, 'in_wavs')\n",
        "\n",
        "os.rmdir(PROJECT_PATH+'matched_wavs_2019')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yr9_70twF7v",
        "colab_type": "text"
      },
      "source": [
        "### Removing bad quality\n",
        "\n",
        "Should remove all files that are not usable for the analysis because later steps in the preprocessing are not written to handle missing files that are usually created during preprocessing.\n",
        "\n",
        "Need to remove those with low quality, these are:\n",
        "- HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163\n",
        "- HM_VHMM006_RT_AUDIO_R14_file_5_(2017_08_06-06_44_59)_ASWMUX221052\n",
        "\n",
        "as well as the one without calls, which was:\n",
        "\n",
        "- HM_VHMM002_HRT_AUDIO_R09_file_5_(2017_08_06-06_44_59)_ASWMUX221110"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNCis5u9wKFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files2delete = ['HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163', \n",
        "                'HM_VHMM006_RT_AUDIO_R14_file_5_(2017_08_06-06_44_59)_ASWMUX221052',\n",
        "                'HM_VHMM002_HRT_AUDIO_R09_file_5_(2017_08_06-06_44_59)_ASWMUX221110']\n",
        "                \n",
        "# Removing segmented audios\n",
        "for file in files2delete:\n",
        "  fileList = glob.glob(AUDIO_OUT+file+'*.wav')\n",
        " # Iterate over the list of filepaths & remove each file.\n",
        "  for filePath in fileList:\n",
        "      try:\n",
        "          os.remove(filePath)\n",
        "      except:\n",
        "          print(\"Error while deleting file : \", filePath)\n",
        "          \n",
        "print(\"Remaining: \"+str(len(glob.glob(AUDIO_OUT+'*')))+\" audio chunks\")\n",
        "\n",
        "# Removing labels files and audio in files\n",
        "for file in files2delete:\n",
        "  try:\n",
        "    os.remove(LABELS_OUT+file+'_labels.csv')\n",
        "  except:\n",
        "    print(\"Error while deleting file csv for : \", file)\n",
        "  try:\n",
        "    os.remove(AUDIO_IN+file+'.wav')\n",
        "  except:\n",
        "    print(\"Error while deleting wav for file : \", file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_mvv_G-fr6Y",
        "colab_type": "text"
      },
      "source": [
        "### Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNBi1GwqS7Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# just a sanity check\n",
        "for wav, label in zip(wav_filepathList, csv_filepathList):\n",
        "  fileID = os.path.basename(wav).replace('.wav','')\n",
        "  numfiles=len(glob.glob(AUDIO_OUT+fileID+'*.wav'))\n",
        "  label_table = pd.read_csv(label)\n",
        "  numlabels = label_table.shape[0]\n",
        "  print(str(numfiles)+' : '+str(numlabels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ytiuafr_3L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from avgn.utils.json import  NoIndentEncoder\n",
        "from avgn.utils.audio import get_samplerate\n",
        "import json\n",
        "from avgn.utils.paths import DATA_DIR\n",
        "import avgn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3xLNSc1Cufc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ID = 'meerkat'\n",
        "SPECIES = \"Suricata suricatta\"\n",
        "\n",
        "def generate_json(call_filepath, audio_filepath, label_filepath):\n",
        "    wav_duration = librosa.get_duration(filename=call_filepath)\n",
        "    wavdate = datetime(year=int(row.year), day=int(row.day), month = int(row.month))\n",
        "    wav_date = wavdate.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    \n",
        "    # wav samplerate and duration\n",
        "    sr = get_samplerate(row.wav_loc.as_posix())\n",
        "    wav_duration = librosa.get_duration(filename=row.wav_loc)\n",
        "    \n",
        "    # wav general information\n",
        "    json_dict = {}\n",
        "    json_dict[\"datetime\"] = wav_date\n",
        "    json_dict[\"samplerate_hz\"] = sr\n",
        "    json_dict[\"samplerate_hz\"] = sr\n",
        "    json_dict[\"length_s\"] = wav_duration\n",
        "    json_dict[\"species\"] = \"Suricata suricatta\"\n",
        "    json_dict[\"common_name\"] = \"Meerkat\"\n",
        "    json_dict[\"wav_loc\"] = row.wav_loc.as_posix()\n",
        "        json_dict = {}\n",
        "    json_dict[\"bout_number\"] = \n",
        "    json_dict[\"original_wav\"] = bout_df.wav_loc.values[0].as_posix()\n",
        "    json_dict[\"noise_loc\"] = noise_out.as_posix()\n",
        "    json_dict[\"indv\"] = \n",
        "    \n",
        "    json_txt = json.dumps(json_dict, cls=NoIndentEncoder, indent=2)\n",
        "    json_out = JSON_OUT+(row.wav_loc.stem + \".JSON\")\n",
        "\n",
        "    # save json\n",
        "    print(json_txt, file=open(json_out, \"w\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0al8HT2Mm53m",
        "colab_type": "text"
      },
      "source": [
        "Example for a single file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qXEXfJ6j1-Y",
        "colab_type": "text"
      },
      "source": [
        "Do the process first with a single file, just taking a random example file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRWyNpO7nufa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_filename = \"HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163_label.CSV\"\n",
        "label_filepath = LABELS_IN+label_filename\n",
        "\n",
        "audio_filename = \"HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163.wav\"\n",
        "audio_filepath = AUDIO_IN+audio_filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXqMn0KGUCJM",
        "colab_type": "text"
      },
      "source": [
        "Generate the chunks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857NwLJQm6kk",
        "colab_type": "code",
        "outputId": "24510c64-3e0d-42e0-fb68-30d3d2106b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "generate_audio_chunks(audio_filepath, label_filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing HM_VHMM007_LT_AUDIO_R11_file_5_(2017_08_06-06_44_59)_ASWMUX221163.wav\n",
            "Parsing...\n",
            "Chunking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WJtTpFMUD7b",
        "colab_type": "text"
      },
      "source": [
        "Looking at results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CAW38ektfB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "durations = [librosa.get_duration(filename=myfile) for myfile in glob.glob(\"*.wav\")]\n",
        "statistics.mean(durations)\n",
        "plt.hist(durations)\n",
        "#print(durations.index(max(durations)))\n",
        "#print(durations[160])\n",
        "#print(max(durations))\n",
        "#y, sr = librosa.load(\"HM_HMB_R11_AUDIO_file_5_(2017_08_24-06_44_59)_ASWMUX221163_call160.wav\", sr=None)\n",
        "#Audio(y, rate=sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep_vqe_lmkSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that adds start and stop times in milliseconds as additional columns\n",
        "# to a dataframe containing start time and duration in format \n",
        "# h:min:s:ms (column 'Start') and min:s:ms (column 'Duration')\n",
        "# Input: labels dataframe (Pandas dataframe)\n",
        "# Output: labels dataframe with additional columns 'start_ms' and\n",
        "#         'stop_ms' (Pandas dataframe)\n",
        "# Example usage: labels = add_startstop_ms(labels)\n",
        "\n",
        "def add_startstop_ms(labels):\n",
        "  \n",
        "  if (labels.shape[0]!=0):\n",
        "  \n",
        "    # Start\n",
        "    start = labels.Start.str.split(\":\", expand=True)\n",
        "    start.columns = ['h', 'min', 's']\n",
        "    start = pd.concat([start.drop(columns=\"s\"),start.s.str.split(\".\", expand=True)], axis=1)\n",
        "\n",
        "    start.columns = ['h', 'min', 's', 'ms']\n",
        "    for i in list(start): start[i] = start[i].astype(str).astype(int)\n",
        "\n",
        "    start['total']= start.apply(lambda row: (row['h']*60*60*1000+ \n",
        "                              row['min']*60*1000+ row['s']*1000+row['ms']), axis = 1)\n",
        "  \n",
        "    duration = labels.Duration.str.split(\":\", expand=True)\n",
        "    duration.columns = ['min', 's']\n",
        "    duration = pd.concat([duration.drop(columns=\"s\"),duration.s.str.split(\".\", expand=True)], axis=1)\n",
        "\n",
        "    duration.columns = ['min', 's', 'ms']\n",
        "    for i in list(duration): duration[i] = duration[i].astype(str).astype(int)\n",
        "\n",
        "    duration['total']= duration.apply(lambda row: (row['min']*60*1000+ \n",
        "                                               row['s']*1000+row['ms']), axis = 1)\n",
        "\n",
        "    labels['start_ms']=start['total']\n",
        "    labels['stop_ms']=start['total']+duration['total']\n",
        "\n",
        "  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcViFbPBs9wG",
        "colab_type": "text"
      },
      "source": [
        "### Removing files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6hDfrTPgzre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(NOISE_OUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQA3h_pJg3Hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1064a3f8-1734-41a3-ff5d-8194e1ae9303"
      },
      "source": [
        "len(os.listdir())"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMLmCaCn_Ynr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fileList = glob.glob('*_call*.wav')\n",
        "fileList = glob.glob('*')\n",
        " # Iterate over the list of filepaths & remove each file.\n",
        "for filePath in fileList:\n",
        "    try:\n",
        "        os.remove(filePath)\n",
        "    except:\n",
        "        print(\"Error while deleting file : \", filePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-ToPnfUfm7-",
        "colab_type": "text"
      },
      "source": [
        "Next, I remove irrelevant rows, i.e. those that mark start, end, synch, beep or are marked as noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrT02HlZdv6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "irrelevant = ['SYNCH', 'START', 'END', 'NOISE', 'BEEP']\n",
        "irrelevant=irrelevant+[item.lower() for item in irrelevant]\n",
        "\n",
        "# relevant labels\n",
        "labels = labels[~labels['Name'].str.contains('|'.join(irrelevant))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qufube5ZhnHu",
        "colab_type": "code",
        "outputId": "7f448d5d-138a-4710-812c-4e332bf10880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3chh5J8ckl6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start\n",
        "start = labels.Start.str.split(\":\", expand=True)\n",
        "start.columns = ['h', 'min', 's']\n",
        "start = pd.concat([start.drop(columns=\"s\"),start.s.str.split(\".\", expand=True)], axis=1)\n",
        "\n",
        "start.columns = ['h', 'min', 's', 'ms']\n",
        "for i in list(start): start[i] = start[i].astype(str).astype(int)\n",
        "\n",
        "start['total']= start.apply(lambda row: (row['h']*60*60*1000+ \n",
        "                     row['min']*60*1000+ row['s']*1000+row['ms']), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDH6ju4XpYgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call duration\n",
        "duration = labels.Duration.str.split(\":\", expand=True)\n",
        "duration.columns = ['min', 's']\n",
        "duration = pd.concat([duration.drop(columns=\"s\"),duration.s.str.split(\".\", expand=True)], axis=1)\n",
        "\n",
        "duration.columns = ['min', 's', 'ms']\n",
        "for i in list(duration): duration[i] = duration[i].astype(str).astype(int)\n",
        "\n",
        "duration['total']= duration.apply(lambda row: (row['min']*60*1000+ \n",
        "                                               row['s']*1000+row['ms']), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m0l9Bi2RFLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add start and stop ms to labels table\n",
        "labels['start_ms']=start['total']\n",
        "labels['stop_ms']=start['total']+duration['total']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxfoiliefe0M",
        "colab_type": "text"
      },
      "source": [
        "The start and stop times in ms are now in the labels table (start_ms, stop_ms)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYNhH2aJRTMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcZYONCBfxJr",
        "colab_type": "text"
      },
      "source": [
        "Now, I can chunk the audio file according to these start and stop times. This will create new, very short audio files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh9pHuSOf55k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd segmented_audios"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEI-nzCxg8Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio = AudioSegment.from_wav(audio_filepath)\n",
        "chunks = labels.apply(lambda row: (audio[row['start_ms']:row['stop_ms']]), axis = 1)\n",
        "\n",
        "chunks.index=range(chunks.shape[0])\n",
        "\n",
        "for index, content in chunks.items():\n",
        "    content.export((audio_filename[:-4]+\"_call\"+str(index)+\".wav\"), format=\"wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Se4uB5NsGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get list of call files to a given file ID\n",
        "# Input: file ID (String)\n",
        "# Output: List of paths to wav call files(List of Strings)\n",
        "# Example use: get_call_filepaths('HM_VHMM003_HLT_AUDIO_R12_file_5_(2017_08_06-06_44_59)_ASWMUX221102.wav')\n",
        "\n",
        "def get_call_filepaths(fileID):\n",
        "  wav_filename = os.path.splitext(os.path.basename(wav_file))[0]\n",
        "  call_filepathList = glob.glob(AUDIO_OUT+file_ID+'*.wav')\n",
        "  return call_filepathList"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}